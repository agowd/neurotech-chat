{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neurotech Chatbot Using RAG"
      ],
      "metadata": {
        "id": "KnFI_cpMSL8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7O-ZPnVSSO6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain faiss-cpu PyMuPDF langchain-community tiktoken"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PIwVVIM8_90z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WE26lO_5_zx4"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import fitz\n",
        "import os\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import faiss\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kkBoN9FXHRiS",
        "outputId": "809aa2a2-c9f9-40ef-dd68-cfe57a399752"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./api_key.txt', 'r') as f:\n",
        "    my_api_key = f.read()"
      ],
      "metadata": {
        "id": "fPjAF-u7H57E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=my_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "KZ4wmj6NAyQh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = client.models.list()\n",
        "for model in models:\n",
        "    print(model.id)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o_D6RwtlElU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF Parsing"
      ],
      "metadata": {
        "id": "jcM310yhSzdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_pdf(path):\n",
        "    doc = fitz.open(path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "ZI1uMOMvRthf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_dir = './articles/raw'\n",
        "\n",
        "texts = []\n",
        "for f in os.listdir(pdf_dir):\n",
        "    pdf_path = os.path.join(pdf_dir, f)\n",
        "    texts.append(parse_pdf(pdf_path))"
      ],
      "metadata": {
        "id": "dN3OleKyTFvC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Post-Processing"
      ],
      "metadata": {
        "id": "aWWOdZRZUG79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunking"
      ],
      "metadata": {
        "id": "jpmGH61XUna0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
        "\n",
        "chunks = []\n",
        "for text in texts:\n",
        "    chunks.extend(text_splitter.split_text(text))"
      ],
      "metadata": {
        "id": "W33I4RwhUIrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "UmbRaL9fUouU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings(api_key=my_api_key)\n",
        "embeddings = embedding.embed_documents(chunks)"
      ],
      "metadata": {
        "id": "98hL0euUUp67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.array(embeddings).astype('float32')\n",
        "index = faiss.IndexFlatL2(embedding_matrix.shape[1])\n",
        "index.add(embedding_matrix)"
      ],
      "metadata": {
        "id": "6LE8wxMZVAXO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query, k=1):\n",
        "    query_embedding = embedding.embed_query(query)\n",
        "    query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
        "\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    retrieved_texts = [chunks[idx] for idx in indices[0]]\n",
        "    return \"\\n\".join(retrieved_texts)"
      ],
      "metadata": {
        "id": "uTsBPABJRhup"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_chatbot(client, query):\n",
        "    \"\"\"Queries the LLM with optional retrieved context.\"\"\"\n",
        "    context = retrieve_context(query)\n",
        "    prompt = f\"Context: {context}\\n\\nUser: {query}\\nAI:\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return context, response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "e_922Tk9_0ro"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is neurotechnology?\"\n",
        "context, response = ask_chatbot(client, query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "TU5J8FTK_7fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0db7e88-450d-4cae-f348-8e4eb68d7912"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neurotechnology involves the development and application of technologies that interact with the nervous system, specifically the brain. The main objective of neurotechnology is to understand the brain's functions better, address neurological disorders, and enhance or restore neural functions. Neurotechnology encompasses a wide range of tools and applications, including:\n",
            "\n",
            "1. **Brain-Computer Interfaces (BCIs)**: These systems enable direct communication between the brain and external devices, often aimed at assisting individuals with significant physical impairments, such as those caused by ALS or spinal cord injuries, to control computers or prosthetic limbs using their thoughts.\n",
            "\n",
            "2. **Neuroprosthetics**: These are artificial devices that replace or enhance the function of damaged or missing neural systems, such as cochlear implants for hearing loss or retinal implants for blindness.\n",
            "\n",
            "3. **Deep Brain Stimulation (DBS)**: This involves implanting electrodes in specific parts of the brain to deliver electrical impulses, often used in treating conditions like Parkinson's disease, essential tremor, or dystonia.\n",
            "\n",
            "4. **Transcranial Magnetic Stimulation (TMS) and Transcranial Direct Current Stimulation (tDCS)**: Non-invasive methods of modulating brain activity used in both research and therapy, TMS and tDCS can investigate brain functions and offer potential treatment for depression and other mental health conditions.\n",
            "\n",
            "5. **Neuroscience-Based Tools and Software**: Devices and applications for imaging or recording brain structure and function, such as MRI, EEG, or fMRI, help researchers and clinicians understand brain activity patterns and diagnose various conditions.\n",
            "\n",
            "6. **Optogenetics and Magnetogenetics**: Emerging approaches that involve using light or magnetic fields to control neurons' activity genetically engineered to express light-sensitive proteins, helping to explore and manipulate brain functions in animal models.\n",
            "\n",
            "Neurotechnology holds great promise for improving our understanding of the brain and offers potential revolutionary therapies for various neurological and psychiatric disorders.\n"
          ]
        }
      ]
    }
  ]
}